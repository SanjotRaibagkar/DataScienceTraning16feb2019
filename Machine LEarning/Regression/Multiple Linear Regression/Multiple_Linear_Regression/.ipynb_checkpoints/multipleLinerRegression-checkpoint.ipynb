{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = b0+ b1*x1+b2*x2+b3*x3 .....\n",
    "\n",
    "\n",
    "Assumption of Liner Regression\n",
    "\n",
    "Lenearity\n",
    "\n",
    "Homoscedastcity \n",
    "\n",
    "Multivariet Normality\n",
    "\n",
    "Independece of error\n",
    "\n",
    "Lack of Multicollineartiy\n",
    "\n",
    "DUMMY Variable Trap - Always remove one dummy variable\n",
    "\n",
    "Building model step by Step\n",
    "\n",
    "\n",
    "Selecting right variable \n",
    "\n",
    "All in -- Throw in all varibale - but not recommended unless you know imp of each and with prior knowledge-- or preparation of backword elimination\n",
    "\n",
    "Backword elimination\n",
    "\n",
    "   Step 1 - Select a significace level to stay in model (ex SL =0.05(50%))\n",
    "   \n",
    "   Step 2- Fit the full model with all possible predictor\n",
    "   \n",
    "   Step3 - highest pValue\n",
    "   \n",
    "   step 4 - remove the predictor\n",
    "   \n",
    "   step 5 = fit the model w/o predictor\n",
    "   \n",
    "           go back to Step3 - uptill point where p value less than SL and Finish\n",
    "   \n",
    "    \n",
    "Forword Selection\n",
    "\n",
    "   Step 1 - Select a significace level to stay in model (ex SL =0.05(50%))\n",
    "   \n",
    "   Step 2 - Fit all regression model y ~Xn, slect the one with  lowest p vallue \n",
    "   \n",
    "   Step 3 - keep this variable and fit all possbile model with one extra predictor \n",
    "   \n",
    "   Step 4 - consider the predictor with lowest p value  if p is < SL then Step 3 else finish\n",
    "   \n",
    "   Step 5 - Keep growing Regression model with adding next variable till  P is >SL\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "Bidirectional elimination(combination of above 2 step )\n",
    "\n",
    "       Step 1\n",
    "score comparision\n",
    "\n",
    "        check all model for 10 columns there will be 1023 model (very time cousuming)\n",
    "        \n",
    "        \n",
    " Will use  Backword elimination \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjotraibagkar/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sanjotraibagkar/anaconda/lib/python3.5/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\"\"\"\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159796, 132582.27760816, 132447.73845175,  71976.09851259,\n",
       "       178537.48221055, 116161.24230164,  67851.69209676,  98791.73374687,\n",
       "       113969.43533012, 167921.06569551])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
